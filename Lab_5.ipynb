{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0fdBiQrC6R6NGDJ1iS3gU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mad7art/work_shop/blob/master/Lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNZ2v_fu5LsE"
      },
      "source": [
        "# Setting up work directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PFF3AdOHLcy9",
        "outputId": "07a09c20-83f7-4033-d2e3-5891762e555e"
      },
      "source": [
        "%mkdir ./sample_data/Lab_5\n",
        "%ls -a\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data/Lab_5\n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  fish-cat.csv  \u001b[01;34m.ipynb_checkpoints\u001b[0m/  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mval\u001b[0m/\n",
            "/content/sample_data/Lab_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ4SAl0U48Px"
      },
      "source": [
        "#**Downloading images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ese8Cb85K7y"
      },
      "source": [
        "#Downloading images into corresponding folders\n",
        "from csv import reader\n",
        "import requests\n",
        "from csv import DictReader\n",
        "\n",
        "#open file in read mode\n",
        "with open('./fish-cat.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_dict_reader = DictReader(read_obj)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    file_name_index = 1\n",
        "    for row in csv_dict_reader:\n",
        "        #Reading in a row from csv\n",
        "        url = row['url']\n",
        "        className = row['class']\n",
        "        typeName = row['type']\n",
        "        print(file_name_index)\n",
        "        try:\n",
        "          #Downloading file\n",
        "          r = requests.get(url, timeout=(5, 14), allow_redirects=True)\n",
        "          if r.ok:\n",
        "            #Saving file\n",
        "            open(typeName + '/' + className + '/' + 'Image_' + str(file_name_index) + '.jpg', 'wb').write(r.content)\n",
        "            file_name_index = file_name_index + 1\n",
        "        except:\n",
        "          print('Failed to download:' + url)\n",
        "    print(file_name_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6Iyzb2ikRChe",
        "outputId": "ea57239b-9b06-4735-fc00-a3f5a267ba73"
      },
      "source": [
        "%ls ./train/cat/ | wc -l\n",
        "%ls ./train/fish/ | wc -l\n",
        "%ls ./val/cat/ | wc -l\n",
        "%ls ./val/fish/ | wc -l\n",
        "%ls ./test/cat/ | wc -l\n",
        "%ls ./test/fish/ | wc -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422\n",
            "393\n",
            "87\n",
            "35\n",
            "91\n",
            "69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAWWICrx-xpc"
      },
      "source": [
        "#Removing hidden directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rdITJrL-2B-"
      },
      "source": [
        "!rmdir /content/sample_data/Lab_5/train/.ipynb_checkpoints\n",
        "!rmdir /content/sample_data/Lab_5/test/.ipynb_checkpoints\n",
        "!rmdir /content/sample_data/Lab_5/val/.ipynb_checkpoints"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2MXrPom7E-g"
      },
      "source": [
        "# Simple network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i91ei9pS7DHy",
        "outputId": "b6819a50-fe2b-4162-d01a-bbfbb8d861e1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "#Setting up network class\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self): \n",
        "    super(SimpleNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(12288, 84)\n",
        "    self.fc2 = nn.Linear(84, 50)\n",
        "    self.fc3 = nn.Linear(50,2)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = x.view(-1, 12288)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "  for epoch in range(1, epochs+1):\n",
        "      training_loss = 0.0\n",
        "      valid_loss = 0.0\n",
        "      model.train()\n",
        "      for batch in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          inputs, targets = batch\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "          output = model(inputs)\n",
        "          loss = loss_fn(output, targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          training_loss += loss.data.item() * inputs.size(0)\n",
        "      training_loss /= len(train_loader.dataset)\n",
        "      \n",
        "      model.eval()\n",
        "      num_correct = 0 \n",
        "      num_examples = 0\n",
        "      for batch in val_loader:\n",
        "          inputs, targets = batch\n",
        "          inputs = inputs.to(device)\n",
        "          output = model(inputs)\n",
        "          targets = targets.to(device)\n",
        "          loss = loss_fn(output,targets) \n",
        "          valid_loss += loss.data.item() * inputs.size(0)\n",
        "          correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
        "          num_correct += torch.sum(correct).item()\n",
        "          num_examples += correct.shape[0]\n",
        "      valid_loss /= len(val_loader.dataset)\n",
        "\n",
        "      print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "      valid_loss, num_correct / num_examples))\n",
        "\n",
        "#Building datasets\n",
        "#Setting up transformation from image to tensor\n",
        "transforms = transforms.Compose([\n",
        "  transforms.Resize((64,64)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "  std=[0.229, 0.224, 0.225] )\n",
        "  ])\n",
        "\n",
        "#Train set\n",
        "train_data_path = \"./train\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=transforms)\n",
        "print(train_data)\n",
        "\n",
        "#Validation set\n",
        "val_data_path = \"./val/\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=transforms)\n",
        "print(val_data)\n",
        "\n",
        "#Test set\n",
        "test_data_path = \"./test/\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=transforms)\n",
        "print(test_data)\n",
        "\n",
        "#Building data loaders\n",
        "batch_size = 64\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "simplenet = SimpleNet()\n",
        "\n",
        "#Initializing optimizer\n",
        "optimizer = optim.Adam(simplenet.parameters(), lr=0.001)\n",
        "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader, 20)\n",
        "torch.save(simplenet, \"/simplenet\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 806\n",
            "    Root location: ./train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 110\n",
            "    Root location: ./val/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 160\n",
            "    Root location: ./test/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )\n",
            "Epoch: 1, Training Loss: 3.12, Validation Loss: 4.16, accuracy = 0.36\n",
            "Epoch: 2, Training Loss: 2.36, Validation Loss: 2.52, accuracy = 0.33\n",
            "Epoch: 3, Training Loss: 1.79, Validation Loss: 0.72, accuracy = 0.74\n",
            "Epoch: 4, Training Loss: 0.70, Validation Loss: 0.69, accuracy = 0.71\n",
            "Epoch: 5, Training Loss: 0.49, Validation Loss: 0.64, accuracy = 0.75\n",
            "Epoch: 6, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.75\n",
            "Epoch: 7, Training Loss: 0.31, Validation Loss: 0.64, accuracy = 0.76\n",
            "Epoch: 8, Training Loss: 0.26, Validation Loss: 0.63, accuracy = 0.75\n",
            "Epoch: 9, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.77\n",
            "Epoch: 10, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.75\n",
            "Epoch: 11, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.75\n",
            "Epoch: 12, Training Loss: 0.14, Validation Loss: 0.68, accuracy = 0.75\n",
            "Epoch: 13, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.75\n",
            "Epoch: 14, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.75\n",
            "Epoch: 15, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.75\n",
            "Epoch: 16, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.75\n",
            "Epoch: 17, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.76\n",
            "Epoch: 18, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.75\n",
            "Epoch: 19, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.75\n",
            "Epoch: 20, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGxAJTUTd54O"
      },
      "source": [
        "# Predictions for fish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o_XIAGkXUAPf",
        "outputId": "08ea3c3c-0fba-472d-fef0-6fbb14541e62"
      },
      "source": [
        "from PIL import Image, ImageFile\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "labels = ['cat','fish']\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "  transforms.Resize((64,64)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "  std=[0.229, 0.224, 0.225] )\n",
        "  ])\n",
        "\n",
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "\n",
        "file_name_index = 994\n",
        "for file_name_index in range(994, 1062): #indexes of fish files in test folder\n",
        "  img = Image.open(\"./test/fish/Image_\" + str(file_name_index) + \".jpg\") \n",
        "  img = transforms(img).to('cpu')\n",
        "  img = torch.unsqueeze(img, 0)\n",
        "\n",
        "  simplenet.eval()\n",
        "  prediction = F.softmax(simplenet(img), dim=1)\n",
        "  prediction = prediction.argmax()\n",
        "  if labels[prediction] == 'fish':\n",
        "    correct += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "  file_name_index += 1\n",
        "  total += 1\n",
        "\n",
        "print('Correct: ' + str(correct))\n",
        "print('Wrong: ' + str(wrong))\n",
        "print('Total: ' + str(total))\n",
        "print(\"Accuracy: %.2f%%\" % ((correct/total)*100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct: 52\n",
            "Wrong: 16\n",
            "Total: 68\n",
            "Accuracy: 76.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqvegI3peBVz"
      },
      "source": [
        "# Predictions for cat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xyMkm_mFeInG",
        "outputId": "bf4e12dc-3fab-4061-c08f-d4a2434191fc"
      },
      "source": [
        "from PIL import Image, ImageFile\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "labels = ['cat','fish']\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "  transforms.Resize((64,64)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "  std=[0.229, 0.224, 0.225] )\n",
        "  ])\n",
        "\n",
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "\n",
        "file_name_index = 994\n",
        "for file_name_index in range(423, 513): #indexes of fish files in test folder\n",
        "  img = Image.open(\"./test/cat/Image_\" + str(file_name_index) + \".jpg\") \n",
        "  img = transforms(img).to('cpu')\n",
        "  img = torch.unsqueeze(img, 0)\n",
        "\n",
        "  simplenet.eval()\n",
        "  prediction = F.softmax(simplenet(img), dim=1)\n",
        "  prediction = prediction.argmax()\n",
        "  if labels[prediction] == 'cat':\n",
        "    correct += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "  file_name_index += 1\n",
        "  total += 1\n",
        "\n",
        "print('Correct: ' + str(correct))\n",
        "print('Wrong: ' + str(wrong))\n",
        "print('Total: ' + str(total))\n",
        "print(\"Accuracy: %.2f%%\" % ((correct/total)*100))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct: 68\n",
            "Wrong: 22\n",
            "Total: 90\n",
            "Accuracy: 75.56%\n"
          ]
        }
      ]
    }
  ]
}